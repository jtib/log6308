# Il suffit � pr�sent de prendre, parmi les citations r�f�renc�es par l'article 422908, celles qui ont le meilleur pageRank.
# Domaine de recherche
S <- m.matrix['422908',]
S <- S[S==1]
S
# Matrice correspondante
colonnes.S <- strsplit(names(S), ',')
lignes.S <- lapply(names(S), function(str) strsplit(str, 'X')[[1]][2])
tmp <- subset(m.matrix, rownames(m.matrix) %in% lignes.S)
mat.S <- subset(tmp,, colnames(tmp) %in% colonnes.S)
# Calcul des pageRanks pour l'ensemble S
n.S <- ncol(mat.S)
pr.first.S <- rep(1,n.S)
ranks.S <- pageRank(mat.S, d, pr.first.S)
ranks.S
# On ordonne
ranks.S.order <- ranks.S[order(-ranks.S),,drop=FALSE]
# Vu le peu de citations pr�sentes dans la base de donn�es, on se limitera � recommander les 5 premi�res.
names(ranks.S.order[1:5,])
# Variante : utilisation du domaine S', qui inclut les citations des citations
# La matrice d'adj
rm(list = ls())
library(Matrix)
d = 0.6
m = read.table("citeseer.rtable")
m.matrix <- data.matrix(m)
m.matrix
eps <- 0.001
pageRank <- function(mat, D, pr.init) {
N <- ncol(mat)
pr.prev <- pr.init
cs <- colSums(mat)
cs[cs==0] <- 1
pr <- (1-D)/N + (D * mat %*% (pr.prev/cs))
while(abs(max(pr-pr.prev))>=eps) {
pr.prev <- pr
pr <- (1-D)/N + (D * mat %*% (pr.prev/cs))
}
return(pr)
}
n <- ncol(m)
pr.first.all <- rep(1,n)
ranks.all <- pageRank(m.matrix, d, pr.first.all)
ranks.all
S <- m.matrix['422908',]
S <- S[S==1]
S
colonnes.S <- strsplit(names(S), ',')
lignes.S <- lapply(names(S), function(str) strsplit(str, 'X')[[1]][2])
tmp <- subset(m.matrix, rownames(m.matrix) %in% lignes.S)
mat.S <- subset(tmp,, colnames(tmp) %in% colonnes.S)
n.S <- ncol(mat.S)
pr.first.S <- rep(1,n.S)
ranks.S <- pageRank(mat.S, d, pr.first.S)
ranks.S
ranks.S.order <- ranks.S[order(-ranks.S),,drop=FALSE]
names(ranks.S.order[1:5,])
m.matrix.square <- m.matrix %&% m.matrix
m.prime <- m.matrix | m.matrix.square
diag(m.prime) <- FALSE
m.prime
S.prime <- m.prime['422908',]
S.prime <- S.prime[S.prime==1]
S.prime
colonnes.S.prime <- strsplit(names(S.prime), ',')
lignes.S.prime <- lapply(names(S.prime), function(str) strsplit(str, 'X')[[1]][2])
tmp.prime <- subset(as.matrix(m.prime), rownames(m.prime) %in% lignes.S.prime)
rm(list = ls())
library(Matrix)
d = 0.6
m = read.table("citeseer.rtable")
m.matrix <- data.matrix(m)
m.matrix
eps <- 0.001
pageRank <- function(mat, D, pr.init) {
N <- ncol(mat)
pr.prev <- pr.init
cs <- colSums(mat)
cs[cs==0] <- 1
pr <- (1-D)/N + (D * mat %*% (pr.prev/cs))
while(abs(max(pr-pr.prev))>=eps) {
pr.prev <- pr
pr <- (1-D)/N + (D * mat %*% (pr.prev/cs))
}
return(pr)
}
n <- ncol(m)
pr.first.all <- rep(1,n)
ranks.all <- pageRank(m.matrix, d, pr.first.all)
ranks.all
S <- m.matrix['422908',]
S <- S[S==1]
S
colonnes.S <- strsplit(names(S), ',')
lignes.S <- lapply(names(S), function(str) strsplit(str, 'X')[[1]][2])
tmp <- subset(m.matrix, rownames(m.matrix) %in% lignes.S)
mat.S <- subset(tmp,, colnames(tmp) %in% colonnes.S)
n.S <- ncol(mat.S)
pr.first.S <- rep(1,n.S)
ranks.S <- pageRank(mat.S, d, pr.first.S)
ranks.S
ranks.S.order <- ranks.S[order(-ranks.S),,drop=FALSE]
names(ranks.S.order[1:5,])
m.matrix.square <- m.matrix %&% m.matrix
m.prime <- m.matrix | m.matrix.square
diag(m.prime) <- FALSE
m.prime
S.prime <- m.prime['422908',]
S.prime <- S.prime[S.prime==1]
S.prime
colonnes.S.prime <- strsplit(names(S.prime), ',')
lignes.S.prime <- lapply(names(S.prime), function(str) strsplit(str, 'X')[[1]][2])
tmp.prime <- subset(as.matrix(m.prime), rownames(m.prime) %in% lignes.S.prime)
mat.S.prime <- subset(tmp.prime,, colnames(tmp.prime) %in% colonnes.S.prime)
n.S.prime <- ncol(mat.S.prime)
pr.first.S.prime <- rep(1,n.S.prime)
ranks.S.prime <- pageRank(mat.S.prime, d, pr.first.S.prime)
ranks.S.prime
ranks.S.prime.order <- ranks.S.prime[order(-ranks.S.prime),,drop=FALSE]
names(ranks.S.prime.order[1:5,])
names(ranks.S.order[1:10,])
length(names(ranks.S.order[1:10,])[names(ranks.S.order[1:10,]) %in% names(ranks.S.prime.order[1:10,])])
m2 = as.matrix(m)
avgCitationParArticle = mean(rowSums(m))
corSimL <- function(item_no1,item_no2, mat = m2){
item1 = mat[item_no1,]
item2 = mat[item_no2,]
if( sum(item1)== 0 || sum(item2)==0)
return(0)
else
return(cor(item1,item2,use = 'pairwise.complete.obs', method = 'pearson'))
}
cosSimL <- function(item_no1,item_no2, mat = m2) {
item1 = mat[item_no1,]
item2 = mat[item_no2,]
if( sum(item1*item2)== 0)
return(0)
else
sum(item1 * item2)/( sqrt(sum(item1^2) * sum(item2^2))  )
}
hammingSimL <- function(item_no1,item_no2, mat = m2) {
item1 = mat[item_no1,]
item2 = mat[item_no2,]
if( sum(item1)== 0 || sum(item2)==0)
return(-10000)
else
a = abs(item1[item1+item2>0]-item2[item1+item2>0])
return(-sum(a/length(a)))
}
corSimC <- function(item_no1,item_no2, mat){
item1 = m[item_no1]
item2 = m[item_no2]
if( sum(item1)== 0 || sum(item2)==0)
return(0)
else
return(cor(item1,item2,use = 'pairwise.complete.obs', method = 'pearson'))
}
cosSimC <- function(item_no1,item_no2, mat) {
item1 = m[item_no1]
item2 = m[item_no2]
if( sum(item1*item2)== 0)
return(0)
else
sum(item1 * item2)/( sqrt(sum(item1^2) * sum(item2^2))  )
}
hammingSimC <- function(item_no1,item_no2, mat) {
item1 = m[item_no1]
item2 = m[item_no2]
if( sum(item1)== 0 || sum(item2)==0)
return(-10000)
else
a = abs(item1[item1+item2>0]-item2[item1+item2>0])
return(-sum(a/length(a)))
}
similarities <- function(item_no,method_of_similarity, mat = m2){
res = seq(1,1090);
similarities = sapply( res, FUN = function(x) method_of_similarity(x,item_no, mat))
return(c(similarities))
}
recommandations <- function(article_line, number_of_recommendations = 5,method_of_similarity = cosSimL, mat = m2) {
scores = similarities(article_line,method_of_similarity, mat)
res=sort(scores, decreasing = TRUE, index.return = TRUE)
res <- setNames(res$x, names(m)[res$ix])[1:number_of_recommendations+1]
if (res[1]==article_line)
return(res[2:length(res)])
else
return(res[1:length(res)])
}
recommandationsNames <- function(article_name, number_of_recommendations = 5, method_of_similarity = cosSimilarity, mat = m2) {
al = match(article_name, names(m))
reco_lines = recommandations(al,number_of_recommendations, method_of_similarity, mat)
return(reco_lines)
}
recommandationsNames("X422908",10,corSimL)
rCosL1 <- recommandationsNames("X422908",10,cosSimL)
rHamL1 <- recommandationsNames("X422908",10,hammingSimL)
recommandationsNames("X422908",10,corSimC)
rCosC1 <- recommandationsNames("X422908",10,cosSimC)
rHamC1 <- recommandationsNames("X422908",10,hammingSimC)
similariteCos <- similarities(747,cosSimL)
length(unique(similariteCos))
m3 <- m2 %*% m2
mean(rowSums(m3))
mTranspose <- t(m2)
bigM <- cbind(m2,mTranspose,m3)
rCosBig <- recommandationsNames("X422908",10,hammingSimL,bigM)
recommandationsNames("X422908",10,corSimL,bigM)
rHamBig <- recommandationsNames("X422908",10,cosSimL,bigM)
similariteCos <- similarities(747,hammingSimL, bigM)
length(unique(similariteCos))
PageRankNames <- names(ranks.S.order[1:10,])
PNR <- sapply(PageRankNames, FUN = function(x) paste("X",x,sep=''))
length(PNR[PNR %in% names(rCosBig)])
length(PNR[PNR %in% names(rHamBig)])
length(PNR[PNR %in% names(rCosL1)])
length(PNR[PNR %in% names(rCosC1)])
length(PNR[PNR %in% names(rHamL1)])
length(PNR[PNR %in% names(rHamC1)])
articlesCites <- m[,m["X422908"]==1]
similaritesParCitation <- function(articleName, method_of_similarity = cosSimL,mat = m2){
articlesCites <- m[,m[articleName]==1]
indices = match(names(articlesCites),names(m))
scores = sapply(indices, FUN = function(x) similarities(x,method_of_similarity,mat))
return(rowSums(scores))
}
recommandationsParVoisinage <- function(article_name, number_of_recommendations = 5,method_of_similarity = cosSimL, mat = m2) {
scores = similaritesParCitation(article_name,method_of_similarity, mat)
res=sort(scores, decreasing = TRUE, index.return = TRUE)
res <- setNames(res$x, names(m)[res$ix])[1:number_of_recommendations+1]
if (res[1]==article_name)
return(res[2:length(res)])
else
return(res[1:length(res)-1])
}
rVoisinage <- recommandationsParVoisinage("X422908",10,hammingSimL)
length(rCosL1[names(rCosL1) %in% names(rVoisinage)])
length(PNR[PNR %in% names(rVoisinage)])
replace.rand <- function(vec){
ind <- names(vec[vec==1][sample(length(vec[vec==1]),1)])
vec[vec==1][ind] <- 0
return(vec)
}
division2 <- function(mat, train.perc){
N <- nrow(mat)
train.nb <- round(train.perc*N/100)
nonnull <- match(row.names(m[-rowSums(m)!=0,]),row.names(m))
#indices o� on change un truc
test <- sample(nonnull, train.nb)
set.train <- mat[-test,]
set.test.full <- mat[test,]
mat[test,] <- t(apply(mat[test,], 1, replace.rand))
# Retrait d'une citation
# Ajout des articles incomplets � l'ensemble d'entra�nement
return(list(mat, test, set.test.full))
}
division2 <- function(mat, train.perc){
N <- nrow(mat)
train.nb <- round(train.perc*N/100)
#indices o� on change un truc
test <- sample.int(nrow(mat), train.nb)
set.train <- mat[-test,]
set.test.full <- mat[test,]
mat[test,] <- t(apply(mat[test,], 1, replace.rand))
# Retrait d'une citation
# Ajout des articles incomplets � l'ensemble d'entra�nement
return(list(mat, test, set.test.full))
}
mtest <- m
l = division2(mtest,10)
trainSet <- as.matrix(l[[1]])
namesOfTrainSet <- names(m)[l[[2]]]
estimatedPredict <- sapply(namesOfTrainSet , FUN = function(x) recommandationsNames(x ,1,cosSimL,trainSet))
namesTrainSet <- sapply(names(estimatedPredict), FUN = function(x) {strsplit(x,'[.]')[[1]][1]})
predIndice <- sapply(names(estimatedPredict), FUN = function(x) strsplit(x,'[.]')[[1]][2])
predIndice2 <- sapply(predIndice, function(x) substr(x,2,nchar(x)))
sort(estimatedPredict)
mReconstruit <- m
a <- predIndice2
for(zz in predIndice2)
{
for(j in namesOfTrainSet){
if (estimatedPredict[match(j,namesOfTrainSet)] != 0)
{mReconstruit[zz,j] = 1}
}
}
sum(m - trainSet)
sum(m - mReconstruit)
sum(mReconstruit-trainSet)
rm(list = ls())
library(Matrix)
d = 0.6
m = read.table("citeseer.rtable")
load("~/Documents/etudes/Poly/aut2017/log6308/tp/TP2/citeseer.rtable")
setwd("~/Documents/etudes/Poly/aut2017/log6308/tp/TP2")
m = read.table("citeseer.rtable")
m.matrix <- data.matrix(m)
m.matrix
eps <- 0.001
pageRank <- function(mat, D, pr.init) {
N <- ncol(mat)
pr.prev <- pr.init
cs <- colSums(mat)
cs[cs==0] <- 1
pr <- (1-D)/N + (D * mat %*% (pr.prev/cs))
while(abs(max(pr-pr.prev))>=eps) {
pr.prev <- pr
pr <- (1-D)/N + (D * mat %*% (pr.prev/cs))
}
return(pr)
}
n <- ncol(m)
pr.first.all <- rep(1,n)
ranks.all <- pageRank(m.matrix, d, pr.first.all)
ranks.all
S <- m.matrix['422908',]
S <- S[S==1]
S
colonnes.S <- strsplit(names(S), ',')
lignes.S <- lapply(names(S), function(str) strsplit(str, 'X')[[1]][2])
tmp <- subset(m.matrix, rownames(m.matrix) %in% lignes.S)
mat.S <- subset(tmp,, colnames(tmp) %in% colonnes.S)
n.S <- ncol(mat.S)
pr.first.S <- rep(1,n.S)
ranks.S <- pageRank(mat.S, d, pr.first.S)
ranks.S
ranks.S.order <- ranks.S[order(-ranks.S),,drop=FALSE]
names(ranks.S.order[1:5,])
m.matrix.square <- m.matrix %&% m.matrix
m.prime <- m.matrix | m.matrix.square
diag(m.prime) <- FALSE
m.prime
S.prime <- m.prime['422908',]
S.prime <- S.prime[S.prime==1]
S.prime
colonnes.S.prime <- strsplit(names(S.prime), ',')
lignes.S.prime <- lapply(names(S.prime), function(str) strsplit(str, 'X')[[1]][2])
tmp.prime <- subset(as.matrix(m.prime), rownames(m.prime) %in% lignes.S.prime)
mat.S.prime <- subset(tmp.prime,, colnames(tmp.prime) %in% colonnes.S.prime)
n.S.prime <- ncol(mat.S.prime)
pr.first.S.prime <- rep(1,n.S.prime)
ranks.S.prime <- pageRank(mat.S.prime, d, pr.first.S.prime)
ranks.S.prime
ranks.S.prime.order <- ranks.S.prime[order(-ranks.S.prime),,drop=FALSE]
names(ranks.S.prime.order[1:5,])
names(ranks.S.order[1:10,])
length(names(ranks.S.order[1:10,])[names(ranks.S.order[1:10,]) %in% names(ranks.S.prime.order[1:10,])])
m2 = as.matrix(m)
avgCitationParArticle = mean(rowSums(m))
corSimL <- function(item_no1,item_no2, mat = m2){
item1 = mat[item_no1,]
item2 = mat[item_no2,]
if( sum(item1)== 0 || sum(item2)==0)
return(0)
else
return(cor(item1,item2,use = 'pairwise.complete.obs', method = 'pearson'))
}
cosSimL <- function(item_no1,item_no2, mat = m2) {
item1 = mat[item_no1,]
item2 = mat[item_no2,]
if( sum(item1*item2)== 0)
return(0)
else
sum(item1 * item2)/( sqrt(sum(item1^2) * sum(item2^2))  )
}
hammingSimL <- function(item_no1,item_no2, mat = m2) {
item1 = mat[item_no1,]
item2 = mat[item_no2,]
if( sum(item1)== 0 || sum(item2)==0)
return(-10000)
else
a = abs(item1[item1+item2>0]-item2[item1+item2>0])
return(-sum(a/length(a)))
}
corSimC <- function(item_no1,item_no2, mat){
item1 = m[item_no1]
item2 = m[item_no2]
if( sum(item1)== 0 || sum(item2)==0)
return(0)
else
return(cor(item1,item2,use = 'pairwise.complete.obs', method = 'pearson'))
}
cosSimC <- function(item_no1,item_no2, mat) {
item1 = m[item_no1]
item2 = m[item_no2]
if( sum(item1*item2)== 0)
return(0)
else
sum(item1 * item2)/( sqrt(sum(item1^2) * sum(item2^2))  )
}
hammingSimC <- function(item_no1,item_no2, mat) {
item1 = m[item_no1]
item2 = m[item_no2]
if( sum(item1)== 0 || sum(item2)==0)
return(-10000)
else
a = abs(item1[item1+item2>0]-item2[item1+item2>0])
return(-sum(a/length(a)))
}
similarities <- function(item_no,method_of_similarity, mat = m2){
res = seq(1,1090);
similarities = sapply( res, FUN = function(x) method_of_similarity(x,item_no, mat))
return(c(similarities))
}
recommandations <- function(article_line, number_of_recommendations = 5,method_of_similarity = cosSimL, mat = m2) {
scores = similarities(article_line,method_of_similarity, mat)
res=sort(scores, decreasing = TRUE, index.return = TRUE)
res <- setNames(res$x, names(m)[res$ix])[1:number_of_recommendations+1]
if (res[1]==article_line)
return(res[2:length(res)])
else
return(res[1:length(res)])
}
recommandationsNames <- function(article_name, number_of_recommendations = 5, method_of_similarity = cosSimilarity, mat = m2) {
al = match(article_name, names(m))
reco_lines = recommandations(al,number_of_recommendations, method_of_similarity, mat)
return(reco_lines)
}
recommandationsNames("X422908",10,corSimL)
rCosL1 <- recommandationsNames("X422908",10,cosSimL)
rHamL1 <- recommandationsNames("X422908",10,hammingSimL)
recommandationsNames("X422908",10,corSimC)
rCosC1 <- recommandationsNames("X422908",10,cosSimC)
rHamC1 <- recommandationsNames("X422908",10,hammingSimC)
similariteCos <- similarities(747,cosSimL)
length(unique(similariteCos))
m3 <- m2 %*% m2
mean(rowSums(m3))
mTranspose <- t(m2)
bigM <- cbind(m2,mTranspose,m3)
rCosBig <- recommandationsNames("X422908",10,hammingSimL,bigM)
recommandationsNames("X422908",10,corSimL,bigM)
rHamBig <- recommandationsNames("X422908",10,cosSimL,bigM)
similariteCos <- similarities(747,hammingSimL, bigM)
length(unique(similariteCos))
PageRankNames <- names(ranks.S.order[1:10,])
PNR <- sapply(PageRankNames, FUN = function(x) paste("X",x,sep=''))
length(PNR[PNR %in% names(rCosBig)])
length(PNR[PNR %in% names(rHamBig)])
length(PNR[PNR %in% names(rCosL1)])
length(PNR[PNR %in% names(rCosC1)])
length(PNR[PNR %in% names(rHamL1)])
length(PNR[PNR %in% names(rHamC1)])
articlesCites <- m[,m["X422908"]==1]
similaritesParCitation <- function(articleName, method_of_similarity = cosSimL,mat = m2){
articlesCites <- m[,m[articleName]==1]
indices = match(names(articlesCites),names(m))
scores = sapply(indices, FUN = function(x) similarities(x,method_of_similarity,mat))
return(rowSums(scores))
}
recommandationsParVoisinage <- function(article_name, number_of_recommendations = 5,method_of_similarity = cosSimL, mat = m2) {
scores = similaritesParCitation(article_name,method_of_similarity, mat)
res=sort(scores, decreasing = TRUE, index.return = TRUE)
res <- setNames(res$x, names(m)[res$ix])[1:number_of_recommendations+1]
if (res[1]==article_name)
return(res[2:length(res)])
else
return(res[1:length(res)-1])
}
rVoisinage <- recommandationsParVoisinage("X422908",10,hammingSimL)
length(rCosL1[names(rCosL1) %in% names(rVoisinage)])
length(PNR[PNR %in% names(rVoisinage)])
replace.rand <- function(vec){
ind <- names(vec[vec==1][sample(length(vec[vec==1]),1)])
vec[vec==1][ind] <- 0
return(vec)
}
division2 <- function(mat, train.perc){
N <- nrow(mat)
train.nb <- round(train.perc*N/100)
nonnull <- match(row.names(m[-rowSums(m)!=0,]),row.names(m))
#indices o� on change un truc
test <- sample(nonnull, train.nb)
set.train <- mat[-test,]
set.test.full <- mat[test,]
mat[test,] <- t(apply(mat[test,], 1, replace.rand))
# Retrait d'une citation
# Ajout des articles incomplets � l'ensemble d'entra�nement
return(list(mat, test, set.test.full))
}
division2 <- function(mat, train.perc){
N <- nrow(mat)
train.nb <- round(train.perc*N/100)
#indices o� on change un truc
test <- sample.int(nrow(mat), train.nb)
set.train <- mat[-test,]
set.test.full <- mat[test,]
mat[test,] <- t(apply(mat[test,], 1, replace.rand))
# Retrait d'une citation
# Ajout des articles incomplets � l'ensemble d'entra�nement
return(list(mat, test, set.test.full))
}
mtest <- m
l = division2(mtest,10)
trainSet <- as.matrix(l[[1]])
namesOfTrainSet <- names(m)[l[[2]]]
estimatedPredict <- sapply(namesOfTrainSet , FUN = function(x) recommandationsNames(x ,1,cosSimL,trainSet))
namesTrainSet <- sapply(names(estimatedPredict), FUN = function(x) {strsplit(x,'[.]')[[1]][1]})
predIndice <- sapply(names(estimatedPredict), FUN = function(x) strsplit(x,'[.]')[[1]][2])
predIndice2 <- sapply(predIndice, function(x) substr(x,2,nchar(x)))
sort(estimatedPredict)
mReconstruit <- m
a <- predIndice2
for(zz in predIndice2)
{
for(j in namesOfTrainSet){
if (estimatedPredict[match(j,namesOfTrainSet)] != 0)
{mReconstruit[zz,j] = 1}
}
}
sum(m - trainSet)
sum(m - mReconstruit)
sum(mReconstruit-trainSet)
